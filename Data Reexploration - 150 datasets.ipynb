{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ReExploration - 150 models\n",
    "Data Exploration consists of the entire process of finding your data, converting it into data that can be manipulated in code, extracting features from the data, cleaning it,  and finally constructing files that contain directly feedable features for an ANN or any machine learning model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from statistics import mean, mode, median, stdev\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieval\n",
    "For this project I chose 3 data sources:\n",
    "1. Tiingo: A financial research platform dedicated to creating innovative financial tools, which provides an API for downloading stock data.\n",
    "2. IEX: Investors Exchange is a fair, simple and transparent stock exchange dedicated to investor and issuer protection, and also provides an API.\n",
    "3. Yahoo Finance: It provides financial news, data and commentary including stock quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to download data from Tiingo and IEX we must provide an API key, \n",
    "# which can be found in your site's respective account page.\n",
    "# My account's keys are stored as environment variables and correspond to free accounts.\n",
    "\n",
    "tiingo_api_key = os.environ['TIINGO_API_KEY']\n",
    "iex_api_key = os.environ['IEX_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing all tickers listed by NASDAQ-100 Technology index. \n",
    "\n",
    "tickers_file = 'ndxt_tickers.txt'\n",
    "\n",
    "\n",
    "# Directory tree to create for data processing.\n",
    "\n",
    "data_dir = 'data_2/' #this directory must already exist.\n",
    "raw_data_dir = data_dir + 'raw/'\n",
    "processed_data_dir = data_dir + 'processed/'\n",
    "final_data_dir = data_dir + 'final/'\n",
    "\n",
    "\n",
    "# We will train different models that can predict different time ranges in the stock calendar.\n",
    "\n",
    "time_range = [1, 5, 10, 20, 90, 270]\n",
    "periods = [5, 10, 20, 90, 270]\n",
    "time_words = {1:'day', 5:'week', 10:'two_weeks', 20:'month', 90:'four_months', 270:'year'}\n",
    "\n",
    "\n",
    "# Make directories\n",
    "\n",
    "if not os.path.exists(raw_data_dir):\n",
    "    os.makedirs(raw_data_dir)\n",
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir)\n",
    "if not os.path.exists(final_data_dir):\n",
    "    os.makedirs(final_data_dir)\n",
    "for n1 in periods:\n",
    "    for n2 in periods:\n",
    "        if not os.path.exists(processed_data_dir+f'/{n1}_{n2}/'):\n",
    "            os.makedirs(processed_data_dir+f'/{n1}_{n2}/')\n",
    "for t in time_range:\n",
    "    for n1 in periods:\n",
    "        for n2 in periods:\n",
    "            if not os.path.exists(final_data_dir+time_words[t]+f'/{n1}_{n2}/'):\n",
    "                os.makedirs(final_data_dir+time_words[t]+f'/{n1}_{n2}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the stock tickers to be downloaded\n",
    "\n",
    "ndxt_tickers = []\n",
    "with open(data_dir+tickers_file) as f:\n",
    "    for ticker in f:\n",
    "        ndxt_tickers.append(ticker.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data is downloaded and directly transformed into a ``pandas.DataFrame``. Immediately after downloading, the raw data is saved into ``.csv`` files.\n",
    "The data to be downloaded are all the possible stock quotes from companies that are indexed by the _NASDAQ-100 Technology Sector_(^NDXT), as well as the index data itself. Since we are using free accounts to retrieve the data from the mentioned API's, the time range for all downloaded data is the limit of 5 years previous to the current date.\n",
    "As for the ^NDXT data, we are using the ``yfinance`` library created by [Ran Aroussi](https://pypi.org/project/yfinance/). \n",
    "\n",
    "Do not abuse the following block of code, as data retrieval comes from free-tier accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for downloading data and saving it\n",
    "# ****USE ONLY WHEN NECESSARY****\n",
    "\n",
    "# raw_stock_data_tiingo = []\n",
    "# raw_stock_data_iex = []\n",
    "# error_tickers = []\n",
    "\n",
    "# for ticker in sorted(ndxt_tickers):\n",
    "#     try:\n",
    "#         raw_stock_data_tiingo.append(pdr.get_data_tiingo(ticker, api_key= tiingo_api_key))\n",
    "#     except:\n",
    "#         error_tickers.append(ticker)\n",
    "# else: \n",
    "#     if error_tickers:\n",
    "#         try:\n",
    "#             for ticker in error_tickers:\n",
    "#                 raw_stock_data_iex.append(pdr.get_markets_iex(ticker, api_key= tiingo_api_key))\n",
    "#         except:\n",
    "#             print(ticker+ ' was not downloaded.')\n",
    "# raw_index_data_yahoo = yf.download('^NDXT', period='5y')\n",
    "\n",
    "\n",
    "# # Save each stock data in a CSV file\n",
    "\n",
    "# for t in raw_stock_data_tiingo:\n",
    "#     t.to_csv(raw_data_dir + t.index.values[0][0] + '.csv')\n",
    "    \n",
    "# for t in raw_stock_data_iex:\n",
    "#     t.to_csv(raw_data_dir + t.index.values[0][0] + '.csv')\n",
    "    \n",
    "# raw_index_data_yahoo.to_csv(raw_data_dir + '^NDXT.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read downloaded data from files\n",
    "\n",
    "raw_stock_data = []\n",
    "raw_index_data_filename = '^NDXT.csv'\n",
    "raw_stock_data_filenames = [f+'.csv' for f in ndxt_tickers]\n",
    "raw_index_df = pd.read_csv(raw_data_dir + raw_index_data_filename)\n",
    "\n",
    "for filename in raw_stock_data_filenames:\n",
    "    raw_stock_data.append(pd.read_csv(raw_data_dir + filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "In order to manipulate the retireved data, it is necessary to give it proper structure.\n",
    "\n",
    "``raw_stock_data`` is a list containing all stock dataframes, and ``raw_index_df`` is the dataframe containing the ^NDXT data. For every dataframe, their index will be the dates of each stock or index quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reformat date in stocks dataframes, remove time\n",
    "\n",
    "for data in raw_stock_data:\n",
    "    data['date'] = data['date'].map(lambda x: x.split()[0])\n",
    "\n",
    "    \n",
    "# Volume is not a given data for the index quotes.\n",
    "\n",
    "raw_index_df.drop(columns='Volume', inplace=True)\n",
    "\n",
    "\n",
    "# Rename index columns to lowercase\n",
    "\n",
    "raw_index_df.columns = ['date', 'open', 'high', 'low', 'close', 'adjClose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every stock dataframe will also contain its ticker symbol as part of their index. Also remove unnecessary information like dividends and splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign symbol and date as index identifiers for every stock record\n",
    "\n",
    "for data in raw_stock_data:\n",
    "    data.set_index(['symbol', 'date'], inplace=True, drop=True)\n",
    "    \n",
    "# Assign date as index identifier for index records as well\n",
    "\n",
    "raw_index_df.set_index(['date'], inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Remove unnecessary information\n",
    "\n",
    "for df in raw_stock_data: df.drop(columns=['divCash', 'splitFactor'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very crucial part for the following data processing is making sure that every dataframe, both stocks and index, contain the same ranges of data. This is because the final features will be a mix of individual stock quotes with index quotes. Since we are not guaranteed that all the downloaded data contains the same time ranges, we must find the oldest last date among all quotes, and also the newest first date for all data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the oldest final date and newest starting date\n",
    "\n",
    "last_dates = [raw_index_df.index[-1]]\n",
    "first_dates = [raw_index_df.index[0]]\n",
    "\n",
    "for df in raw_stock_data:\n",
    "    dates = []\n",
    "    \n",
    "    for idx in df.index:\n",
    "        dates.append(idx[1])\n",
    "    \n",
    "    last_dates.append(max(dates))\n",
    "    first_dates.append(min(dates))\n",
    "\n",
    "last_date = min(last_dates)\n",
    "first_date = max(first_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the found time ranges, we can trim the dataframes to make sure they all contain the same respective dates for their data. Then, reverse dataframes so that the latest quote comes first, and the oldest quote goes last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both DataFrames have the same final date (as close to today as possible)\n",
    "\n",
    "while(raw_index_df.index[0] > last_date):\n",
    "    raw_index_df.pop(raw_index_df.index[0])\n",
    "\n",
    "while(raw_index_df.index[-1] < first_date):\n",
    "    raw_index_df.pop(raw_index_df.index[-1])\n",
    "        \n",
    "for df in raw_stock_data:\n",
    "    while(df.index[0][1] > last_date):\n",
    "        df.pop(df.index[0])\n",
    "    while(df.index[-1][1] < first_date):\n",
    "        df.pop(df.index[-1])\n",
    "        \n",
    "        \n",
    "# Reverse stock and index records\n",
    "\n",
    "for df in raw_stock_data:\n",
    "    df = df.sort_index(ascending=False, inplace=True)\n",
    "raw_index_df = raw_index_df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(stock_df, since = 1):\n",
    "    '''Function for labeling the trend in stock data given a period of time.\n",
    "    \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            since (int): time period for which to label trend.\n",
    "        \n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with labels 1 for incresing close price after 'since' days, 0 otherwise.\n",
    "    '''\n",
    "    stock_df.drop(columns='y_'+str(since), inplace=True, errors='ignore')\n",
    "    labels = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            assert i-since >= 0\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            future = stock_df.iloc[i-since]['close']\n",
    "            labels.append(1 if future>today else 0)\n",
    "        except:\n",
    "            labels.append(None)\n",
    "    stock_df.insert(loc=0, column='y_'+str(since), value=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(stock_df, period = 1):\n",
    "    '''Function for calculating the change percentage of closing prices since 'period' days ago.\n",
    "    \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            period (int): time period for which to calculate change.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with change percentage.\n",
    "    '''\n",
    "    stock_df.drop(columns='change', inplace=True, errors='ignore')\n",
    "    change = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            previous = stock_df.iloc[i+period]['close']\n",
    "            change.append(100*(today-previous)/previous)\n",
    "        except:\n",
    "            change.append(None)\n",
    "    stock_df.insert(loc=0, column='change', value=change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PMO(stock_df, period = 50):\n",
    "    '''Price Momentum Oscillator.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with PMO.\n",
    "    '''\n",
    "    stock_df.drop(columns='PMO', inplace=True, errors='ignore')\n",
    "    pmo = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            previous = stock_df.iloc[i+period]['close']\n",
    "            pmo.append(today - previous)\n",
    "        except:\n",
    "            pmo.append(None)\n",
    "    stock_df.insert(loc=0, column='PMO', value=pmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(stock_df, period = 50):\n",
    "    '''Relative Strength Index.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a columns 'close' for the closing prices and 'change' in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with RSI.\n",
    "    '''\n",
    "    stock_df.drop(columns='RSI', inplace=True, errors='ignore')\n",
    "    rsi = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            rsi_value = 0\n",
    "            pos = []\n",
    "            neg = []\n",
    "            \n",
    "            for j in range(period):\n",
    "                change = stock_df.iloc[i+j]['change']\n",
    "                if change > 0: \n",
    "                    pos.append(change)\n",
    "                elif change < 0: \n",
    "                    neg.append(abs(change))\n",
    "                    \n",
    "            if not neg:\n",
    "                rsi_value = 100\n",
    "            elif not pos:\n",
    "                rsi_value = 0\n",
    "            else:\n",
    "                pos = sum(pos)/len(pos)\n",
    "                neg = sum(neg)/len(neg)\n",
    "                rsi_value = 100 - (100/(1+(pos/neg)))\n",
    "            rsi.append(rsi_value)\n",
    "        except:\n",
    "            rsi.append(None)\n",
    "    stock_df.insert(loc=0, column='RSI', value=rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI(stock_df, period = 50):\n",
    "    '''Money Flow Index.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a columns 'close' for the closing prices and 'volume', 'high', and 'low' in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with MFI.\n",
    "    '''\n",
    "    stock_df.drop(columns='MFI', inplace=True, errors='ignore')\n",
    "    mfi = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            mfi_value = 0\n",
    "            pos = []\n",
    "            neg = []\n",
    "            typical_prices = []\n",
    "            \n",
    "            for j in range(period):\n",
    "                if not typical_prices: typical_prices.append( mean([stock_df.iloc[i+1]['high'] , stock_df.iloc[i+1]['low'] , stock_df.iloc[i+1]['close']]) ) \n",
    "                tp = (stock_df.iloc[i+j]['high'] + stock_df.iloc[i+j]['low'] + stock_df.iloc[i+j]['close']) / 3\n",
    "                if tp > typical_prices[-1]: \n",
    "                    pos.append( tp * stock_df.iloc[i+j]['volume'] )\n",
    "                elif tp < typical_prices[-1]: \n",
    "                    neg.append( tp * stock_df.iloc[i+j]['volume'] )\n",
    "            \n",
    "            if not neg:\n",
    "                mfi_value = 100\n",
    "            elif not pos:\n",
    "                mfi_value = 0\n",
    "            else:\n",
    "                pos = sum(pos)/len(pos)\n",
    "                neg = sum(neg)/len(neg)\n",
    "                mfi_value = 100 - (100/(1+(pos/neg)))\n",
    "            mfi.append(mfi_value)\n",
    "        except:\n",
    "            mfi.append(None)\n",
    "    stock_df.insert(loc=0, column='MFI', value=mfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(stock_df, period=50):\n",
    "    '''Exponential Moving Average.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with EMA.\n",
    "    '''\n",
    "    stock_df.drop(columns='EMA', inplace=True, errors='ignore')\n",
    "    a = 2/(period + 1)\n",
    "    # There are many ways to calculate the first term of an exponential moving average, so for now\n",
    "    # I'll be using the average of the previous 3 closes\n",
    "    initial_value_range = 3\n",
    "    ema = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        emas = []\n",
    "        try:\n",
    "            \n",
    "            for j in list(reversed(range(period))):\n",
    "                if not emas: emas.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a * tc) + ((1 - a) * emas[-1])\n",
    "                emas.append(this_ema)\n",
    "            \n",
    "            ema.append(emas[-1])\n",
    "        except:\n",
    "            ema.append(None)\n",
    "    stock_df.insert(loc=0, column='EMA', value=ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SO(stock_df, period=50):\n",
    "    '''Stochastic Oscillator.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices, 'high', and 'low' in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with PMO.\n",
    "    '''\n",
    "    stock_df.drop(columns='SO', inplace=True, errors='ignore')\n",
    "    \n",
    "    so = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            tc = stock_df.iloc[i]['close']\n",
    "            ll = min([stock_df.iloc[i+day]['low'] for day in range(period)])\n",
    "            hh = max([stock_df.iloc[i+day]['high'] for day in range(period)])\n",
    "            this_so = ((tc - ll) / (hh - ll)) * 100\n",
    "            so.append(this_so)\n",
    "        except:\n",
    "            so.append(None)\n",
    "    \n",
    "    stock_df.insert(loc=0, column='SO', value=so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(stock_df, p1=12, p2=26):\n",
    "    '''Moving Average Convergence/Divergence.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            p1 (int): time period for which to calculate first EMA.\n",
    "            p2 (int): time period for which to calculate second EMA.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with PMO.\n",
    "    '''\n",
    "    stock_df.drop(columns='MACD', inplace=True, errors='ignore')\n",
    "    \n",
    "    a1 = 2/(p1 + 1)\n",
    "    a2 = 2/(p2 + 1)\n",
    "    initial_value_range = 3\n",
    "    macd = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        ema1 = []\n",
    "        ema2 = []\n",
    "        try:\n",
    "            for j in list(reversed(range(p1))):\n",
    "                if not ema1: ema1.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a1 * tc) + ((1 - a1) * ema1[-1])\n",
    "                ema1.append(this_ema)\n",
    "            \n",
    "            for j in list(reversed(range(p2))):\n",
    "                if not ema2: ema2.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a2 * tc) + ((1 - a2) * ema2[-1])\n",
    "                ema2.append(this_ema)\n",
    "            \n",
    "            macd.append(ema1[-1] - ema2[-1])\n",
    "            \n",
    "        except:\n",
    "            macd.append(None)\n",
    "    \n",
    "    stock_df.insert(loc=0, column='MACD', value=macd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the enormous possibilities of mixing time ranges for features for both index and stock data (150 different datasets in total), as proposed by Madge, the following cell can take several hours to run. Recommended to run in a powerful instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANNs require their feeded features to be normalized values. Therefore, we need to convert all features into ranges from [0,1]. For features that represent percenatges we divide them by 100, and for features with arbitrary ranges we scale them with a ``MinMaxScaler``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1% 0.2% 0.3% 0.4% 0.5% 0.6% 0.7% 0.8% 0.9% 1.0% 1.1% 1.2% 1.3% 1.4% 1.5% 1.6% 1.7% 1.8% 1.9% 2.0% 2.1% 2.2% 2.3% 2.4% 2.5% 2.6% 2.7% 2.8% 2.9% 3.0% 3.1% 3.2% 3.3% 3.4% 3.5% 3.6% 3.7% 3.8% 3.9% 4.0% 4.1% 4.2% 4.3% 4.4% 4.5% 4.6% 4.7% 4.8% 4.9% 5.0% 5.1% 5.2% 5.3% 5.4% 5.5% 5.6% 5.7% 5.8% 5.9% 6.0% 6.1% 6.2% 6.3% 6.4% 6.5% 6.6% 6.7% 6.8% 6.9% 7.0% 7.1% 7.2% 7.3% 7.4% 7.5% 7.6% 7.7% 7.8% 7.9% 8.0% 8.1% 8.2% 8.3% 8.4% 8.5% 8.6% 8.7% 8.8% 8.9% 9.0% 9.1% 9.2% 9.3% 9.4% 9.5% 9.6% 9.7% 9.8% 9.9% 10.0% 10.1% 10.2% 10.3% 10.4% 10.5% 10.6% 10.7% 10.8% 10.9% 11.0% 11.1% 11.2% 11.3% 11.4% 11.5% 11.6% 11.7% 11.8% 11.9% 12.0% 12.1% 12.2% 12.3% 12.4% 12.5% 12.6% 12.7% 12.8% 12.9% 13.0% 13.1% 13.2% 13.3% 13.4% 13.5% 13.6% 13.7% 13.8% 13.9% 14.0% 14.1% 14.2% 14.3% 14.4% 14.5% 14.6% 14.7% 14.8% 14.9% 15.0% 15.1% 15.2% 15.3% 15.4% 15.5% 15.6% 15.7% 15.8% 15.9% 16.0% 16.1% 16.2% 16.3% 16.4% 16.5% 16.6% 16.7% 16.8% 16.9% 17.0% 17.1% 17.2% 17.3% 17.4% 17.5% 17.6% 17.7% 17.8% 17.9% 18.0% 18.1% 18.2% 18.3% 18.4% 18.5% 18.6% 18.7% 18.8% 18.9% 19.0% 19.1% 19.2% 19.3% 19.4% 19.5% 19.6% 19.7% 19.8% 19.9% 20.0% 20.1% 20.2% 20.3% 20.4% 20.5% 20.6% 20.7% 20.8% 20.9% 21.0% 21.1% 21.2% 21.3% 21.4% 21.5% 21.6% 21.7% 21.8% 21.9% 22.0% 22.1% 22.2% 22.3% 22.4% 22.5% 22.6% 22.7% 22.8% 22.9% 23.0% 23.1% 23.2% 23.3% 23.4% 23.5% 23.6% 23.7% 23.8% 23.9% 24.0% 24.1% 24.2% 24.3% 24.4% 24.5% 24.6% 24.7% 24.8% 24.9% 25.0% 25.1% 25.2% 25.3% 25.4% 25.5% 25.6% 25.7% 25.8% 25.9% 26.0% 26.1% 26.2% 26.3% 26.4% 26.5% 26.6% 26.7% 26.8% 26.9% 27.0% 27.1% 27.2% 27.3% 27.4% 27.5% 27.6% 27.7% 27.8% 27.9% 28.0% 28.1% 28.2% 28.3% 28.4% 28.5% 28.6% 28.7% 28.8% 28.9% 29.0% 29.1% 29.2% 29.3% 29.4% 29.5% 29.6% 29.7% 29.8% 29.9% 30.0% 30.1% 30.2% 30.3% 30.4% 30.5% 30.6% 30.7% 30.8% 30.9% 31.0% 31.1% 31.2% 31.3% 31.4% 31.5% 31.6% 31.7% 31.8% 31.9% 32.0% 32.1% 32.2% 32.3% 32.4% 32.5% 32.6% 32.7% 32.8% 32.9% 33.0% 33.1% 33.2% 33.3% 33.4% 33.5% 33.6% 33.7% 33.8% 33.9% 34.0% 34.1% 34.2% 34.3% 34.4% 34.5% 34.6% 34.7% 34.8% 34.9% 35.0% 35.1% 35.2% 35.3% 35.4% 35.5% 35.6% 35.7% 35.8% 35.9% 36.0% 36.1% 36.2% 36.3% 36.4% 36.5% 36.6% 36.7% 36.8% 36.9% 37.0% 37.1% 37.2% 37.3% 37.4% 37.5% 37.6% 37.7% 37.8% 37.9% 38.0% 38.1% 38.2% 38.3% 38.4% 38.5% 38.6% 38.7% 38.8% 38.9% 39.0% 39.1% 39.2% 39.3% 39.4% 39.5% 39.6% 39.7% 39.8% 39.9% 40.0% 40.1% 40.2% 40.3% 40.4% 40.5% 40.6% 40.7% 40.8% 40.9% 41.0% 41.1% 41.2% 41.3% 41.4% 41.5% 41.6% 41.7% 41.8% 41.9% 42.0% 42.1% 42.2% 42.3% 42.4% 42.5% 42.6% 42.7% 42.8% 42.9% 43.0% 43.1% 43.2% 43.3% 43.4% 43.5% 43.6% 43.7% 43.8% 43.9% 44.0% 44.1% 44.2% 44.3% 44.4% 44.5% 44.6% 44.7% 44.8% 44.9% 45.0% 45.1% 45.2% 45.3% 45.4% 45.5% 45.6% 45.7% 45.8% 45.9% 46.0% 46.1% 46.2% 46.3% 46.4% 46.5% 46.6% 46.7% 46.8% 46.9% 47.0% 47.1% 47.2% 47.3% 47.4% 47.5% 47.6% 47.7% 47.8% 47.9% 48.0% 48.1% 48.2% 48.3% 48.4% 48.5% 48.6% 48.7% 48.8% 48.9% 49.0% 49.1% 49.2% 49.3% 49.4% 49.5% 49.6% 49.7% 49.8% 49.9% 50.0% 50.1% 50.2% 50.3% 50.4% 50.5% 50.6% 50.7% 50.8% 50.9% 51.0% 51.1% 51.2% 51.3% 51.4% 51.5% 51.6% 51.7% 51.8% 51.9% 52.0% 52.1% 52.2% 52.3% 52.4% 52.5% 52.6% 52.7% 52.8% 52.9% 53.0% 53.1% 53.2% 53.3% 53.4% 53.5% 53.6% 53.7% 53.8% 53.9% 54.0% 54.1% 54.2% 54.3% 54.4% 54.5% 54.6% 54.7% 54.8% 54.9% 55.0% 55.1% 55.2% 55.3% 55.4% 55.5% 55.6% 55.7% 55.8% 55.9% 56.0% 56.1% 56.2% 56.3% 56.4% 56.5% 56.6% 56.7% 56.8% 56.9% 57.0% 57.1% 57.2% 57.3% 57.4% 57.5% 57.6% 57.7% 57.8% 57.9% 58.0% 58.1% 58.2% 58.3% 58.4% 58.5% 58.6% 58.7% 58.8% 58.9% 59.0% 59.1% 59.2% 59.3% 59.4% 59.5% 59.6% 59.7% 59.8% 59.9% 60.0% 60.1% 60.2% 60.3% 60.4% 60.5% 60.6% 60.7% 60.8% 60.9% 61.0% 61.1% 61.2% 61.3% 61.4% 61.5% 61.6% 61.7% 61.8% 61.9% 62.0% 62.1% 62.2% 62.3% 62.4% 62.5% 62.6% 62.7% 62.8% 62.9% 63.0% 63.1% 63.2% 63.3% 63.4% 63.5% 63.6% 63.7% 63.8% 63.9% 64.0% 64.1% 64.2% 64.3% 64.4% 64.5% 64.6% 64.7% 64.8% 64.9% 65.0% 65.1% 65.2% 65.3% 65.4% 65.5% 65.6% 65.7% 65.8% 65.9% 66.0% 66.1% 66.2% 66.3% 66.4% 66.5% 66.6% 66.7% 66.8% 66.9% 67.0% 67.1% 67.2% 67.3% 67.4% 67.5% 67.6% 67.7% 67.8% 67.9% 68.0% 68.1% 68.2% 68.3% 68.4% 68.5% 68.6% 68.7% 68.8% 68.9% 69.0% 69.1% 69.2% 69.3% 69.4% 69.5% 69.6% 69.7% 69.8% 69.9% 70.0% 70.1% 70.2% 70.3% 70.4% 70.5% 70.6% 70.7% 70.8% 70.9% 71.0% 71.1% 71.2% 71.3% 71.4% 71.5% 71.6% 71.7% 71.8% 71.9% 72.0% 72.1% 72.2% 72.3% 72.4% 72.5% 72.6% 72.7% 72.8% 72.9% 73.0% 73.1% 73.2% 73.3% 73.4% 73.5% 73.6% 73.7% 73.8% 73.9% 74.0% 74.1% 74.2% 74.3% 74.4% 74.5% 74.6% 74.7% 74.8% 74.9% 75.0% 75.1% 75.2% 75.3% 75.4% 75.5% 75.6% 75.7% 75.8% 75.9% 76.0% 76.1% 76.2% 76.3% 76.4% 76.5% 76.6% 76.7% 76.8% 76.9% 77.0% 77.1% 77.2% 77.3% 77.4% 77.5% 77.6% 77.7% 77.8% 77.9% 78.0% 78.1% 78.2% 78.3% 78.4% 78.5% 78.6% 78.7% 78.8% 78.9% 79.0% 79.1% 79.2% 79.3% 79.4% 79.5% 79.6% 79.7% 79.8% 79.9% 80.0% 80.1% 80.2% 80.3% 80.4% 80.5% 80.6% 80.7% 80.8% 80.9% 81.0% 81.1% 81.2% 81.3% 81.4% 81.5% 81.6% 81.7% 81.8% 81.9% 82.0% 82.1% 82.2% 82.3% 82.4% 82.5% 82.6% 82.7% 82.8% 82.9% 83.0% 83.1% 83.2% 83.3% 83.4% 83.5% 83.6% 83.7% 83.8% 83.9% 84.0% 84.1% 84.2% 84.3% 84.4% 84.5% 84.6% 84.7% 84.8% 84.9% 85.0% 85.1% 85.2% 85.3% 85.4% 85.5% 85.6% 85.7% 85.8% 85.9% 86.0% 86.1% 86.2% 86.3% 86.4% 86.5% 86.6% 86.7% 86.8% 86.9% 87.0% 87.1% 87.2% 87.3% 87.4% 87.5% 87.6% 87.7% 87.8% 87.9% 88.0% 88.1% 88.2% 88.3% 88.4% 88.5% 88.6% 88.7% 88.8% 88.9% 89.0% 89.1% 89.2% 89.3% 89.4% 89.5% 89.6% 89.7% 89.8% 89.9% 90.0% 90.1% 90.2% 90.3% 90.4% 90.5% 90.6% 90.7% 90.8% 90.9% 91.0% 91.1% 91.2% 91.3% 91.4% 91.5% 91.6% 91.7% 91.8% 91.9% 92.0% 92.1% 92.2% 92.3% 92.4% 92.5% 92.6% 92.7% 92.8% 92.9% 93.0% 93.1% 93.2% 93.3% 93.4% 93.5% 93.6% 93.7% 93.8% 93.9% 94.0% 94.1% 94.2% 94.3% 94.4% 94.5% 94.6% 94.7% 94.8% 94.9% 95.0% 95.1% 95.2% 95.3% 95.4% 95.5% 95.6% 95.7% 95.8% 95.9% 96.0% 96.1% 96.2% 96.3% 96.4% 96.5% 96.6% 96.7% 96.8% 96.9% 97.0% 97.1% 97.2% 97.3% 97.4% 97.5% 97.6% 97.7% 97.8% 97.9% 98.0% 98.1% 98.2% 98.3% 98.4% 98.5% 98.6% 98.7% 98.8% 98.9% 99.0% 99.1% 99.2% 99.3% 99.4% 99.5% 99.6% 99.7% 99.8% 99.9% 100.0% "
     ]
    }
   ],
   "source": [
    "j=0\n",
    "symbols = []\n",
    "\n",
    "for n1 in periods:\n",
    "    for n2 in periods:\n",
    "        \n",
    "        stocks_df = [df.copy() for df in raw_stock_data]\n",
    "        index_df = raw_index_df.copy()\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        \n",
    "        # Calculate features for index data, MFI is not calculated as it requires volume\n",
    "        if not os.path.exists(processed_data_dir+ f'{n1}_{n2}/^NDXT.csv'):\n",
    "            change(index_df)\n",
    "            MACD(index_df, n1, 2*n1)\n",
    "            SO(index_df, n1)\n",
    "            EMA(index_df, n1)\n",
    "            RSI(index_df, n1)\n",
    "            PMO(index_df, n1)\n",
    "            index_df.fillna(value=pd.np.nan, inplace=True)\n",
    "            \n",
    "            # Normalizing features\n",
    "            idf = index_df[['PMO', 'EMA', 'MACD']]\n",
    "            scaler.fit(idf)\n",
    "            index_df[['PMO', 'EMA', 'MACD']] = scaler.transform(idf)\n",
    "            idf = index_df[['RSI', 'SO']]\n",
    "            index_df[['RSI', 'SO']] = idf/100\n",
    "            \n",
    "            # Saving index file\n",
    "            index_df.to_csv(processed_data_dir+f'{n1}_{n2}/^NDXT.csv')\n",
    "        j += 1\n",
    "        print(f'{round(j*100/(25*(1+len(ndxt_tickers))), 1)}% ', end='')\n",
    "            \n",
    "            \n",
    "        # Calculate features and labels for stock data, this takes a lot of time\n",
    "        for i, df in enumerate(stocks_df):\n",
    "            symbol = df.index[0][0]\n",
    "            if not os.path.exists(processed_data_dir+ f'{n1}_{n2}/{symbol}.csv'):\n",
    "                change(df)\n",
    "                MACD(df, n2, 2*n2)\n",
    "                SO(df, n2)\n",
    "                EMA(df, n2)\n",
    "                MFI(df, n2)\n",
    "                RSI(df, n2)\n",
    "                PMO(df, n2)\n",
    "                for m in time_range:\n",
    "                    labels(df, m)\n",
    "                df.fillna(value=pd.np.nan, inplace=True)\n",
    "                \n",
    "                # Normalizing features\n",
    "                df_ = df[['PMO', 'EMA', 'MACD']]\n",
    "                scaler.fit(df_)\n",
    "                df[['PMO', 'EMA', 'MACD']] = scaler.transform(df_)\n",
    "                df_ = df[['RSI' ,'MFI', 'SO']]\n",
    "                df[['RSI' ,'MFI', 'SO']] = df_/100\n",
    "                \n",
    "                # Saving each stock file\n",
    "                df.to_csv(processed_data_dir+ f'{n1}_{n2}/{symbol}.csv')\n",
    "            j += 1\n",
    "            print(f'{round(j*100/(25*(1+len(ndxt_tickers))), 1)}% ', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data preparation\n",
    "Data has been processed and normalized, and is ready to be unified into feedable train and test datasets. \n",
    "We will produce one test and one train dataset for each of the 150 models to be trained, and each record (each stock market day) of each dataset will contain the following structure.\n",
    "1. Label\n",
    "2. Stock PMO\n",
    "3. Stock EMA\n",
    "4. Stock MACD\n",
    "5. Stock RSI\n",
    "6. Stock MFI\n",
    "7. Stock SO\n",
    "8. Index PMO\n",
    "9. Index EMA\n",
    "10. Index MACD\n",
    "11. Index RSI\n",
    "12. Index SO\n",
    "\n",
    "\n",
    "For each stock symbol and each stock date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67% 1.33% 2.0% 2.67% 3.33% 4.0% 4.67% 5.33% 6.0% 6.67% 7.33% 8.0% 8.67% 9.33% 10.0% 10.67% 11.33% 12.0% 12.67% 13.33% 14.0% 14.67% 15.33% 16.0% 16.67% 17.33% 18.0% 18.67% 19.33% 20.0% 20.67% 21.33% 22.0% 22.67% 23.33% 24.0% 24.67% 25.33% 26.0% 26.67% 27.33% 28.0% 28.67% 29.33% 30.0% 30.67% 31.33% 32.0% 32.67% 33.33% 34.0% 34.67% 35.33% 36.0% 36.67% 37.33% 38.0% 38.67% 39.33% 40.0% 40.67% 41.33% 42.0% 42.67% 43.33% 44.0% 44.67% 45.33% 46.0% 46.67% 47.33% 48.0% 48.67% 49.33% 50.0% 50.67% 51.33% 52.0% 52.67% 53.33% 54.0% 54.67% 55.33% 56.0% 56.67% 57.33% 58.0% 58.67% 59.33% 60.0% 60.67% 61.33% 62.0% 62.67% 63.33% 64.0% 64.67% 65.33% 66.0% 66.67% 67.33% 68.0% 68.67% 69.33% 70.0% 70.67% 71.33% 72.0% 72.67% 73.33% 74.0% 74.67% 75.33% 76.0% 76.67% 77.33% 78.0% 78.67% 79.33% 80.0% 80.67% 81.33% 82.0% 82.67% 83.33% 84.0% 84.67% 85.33% 86.0% 86.67% 87.33% 88.0% 88.67% 89.33% 90.0% 90.67% 91.33% 92.0% 92.67% 93.33% 94.0% 94.67% 95.33% 96.0% 96.67% 97.33% 98.0% 98.67% 99.33% 100.0% "
     ]
    }
   ],
   "source": [
    "# Unify all data into separate training/testing sets\n",
    "\n",
    "j=0\n",
    "for n1 in periods:\n",
    "    for n2 in periods:\n",
    "        stocks_df = [(pd.read_csv(processed_data_dir+f'{n1}_{n2}/{symbol}.csv'), symbol) for symbol in ndxt_tickers]\n",
    "        index_df = pd.read_csv(processed_data_dir+f'{n1}_{n2}/^NDXT.csv')\n",
    "        for t in time_range:\n",
    "            j+=1\n",
    "            train_df_list = []\n",
    "            test_df_list = []\n",
    "            \n",
    "            if not os.path.exists(final_data_dir+time_words[t]+f'/{n1}_{n2}/test/'):\n",
    "                os.makedirs(final_data_dir+time_words[t]+f'/{n1}_{n2}/test/')\n",
    "            if not os.path.exists(final_data_dir+time_words[t]+f'/{n1}_{n2}/train/'):\n",
    "                os.makedirs(final_data_dir+time_words[t]+f'/{n1}_{n2}/train/')\n",
    "            \n",
    "            for df, symbol in stocks_df:\n",
    "                test_train_separation = round((len(df.dropna()))*2/3)\n",
    "                to_concat = [df[['y_'+str(t), 'PMO', 'EMA', 'MACD', 'RSI' ,'MFI', 'SO']], index_df[['PMO', 'EMA', 'MACD', 'RSI', 'SO']]]\n",
    "                concatenated = pd.concat([s.reset_index(drop=True) for s in to_concat], sort=False, axis=1).dropna()\n",
    "                test_train_separation = round((len(concatenated))*2/3)\n",
    "                \n",
    "                concatenated_train = concatenated.iloc[:test_train_separation]\n",
    "                concatenated_test = concatenated.iloc[test_train_separation:]\n",
    "                \n",
    "                train_df_list.append(concatenated_train)\n",
    "                test_df_list.append(concatenated_test)\n",
    "            \n",
    "                concatenated_train.to_csv(final_data_dir+time_words[t]+f'/{n1}_{n2}/train/{symbol}.csv', header=False, index=False)\n",
    "                concatenated_test.to_csv(final_data_dir+time_words[t]+f'/{n1}_{n2}/test/{symbol}.csv', header=False, index=False)\n",
    "            \n",
    "            full_train_df = pd.concat([df for df in train_df_list], axis=0)\n",
    "            full_test_df = pd.concat([df for df in test_df_list], axis=0)\n",
    "\n",
    "            # Save final data\n",
    "            full_train_df.to_csv(final_data_dir+time_words[t]+f'/{n1}_{n2}'+'/train.csv', header=False, index=False)\n",
    "            full_test_df.to_csv(final_data_dir+time_words[t]+f'/{n1}_{n2}'+'/test.csv', header=False, index=False)\n",
    "            print(f'{round(j*100/(len(periods)*len(periods)*len(time_range)), 2)}% ', end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
