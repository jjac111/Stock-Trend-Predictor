{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Trend Predictor\n",
    "__Juan Javier Arosemena__\n",
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from statistics import mean, mode, median, stdev\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = [1, 5, 10, 20, 90, 270]\n",
    "time_words = {1:'day', 5:'week', 10:'two_weeks', 20:'month', 90:'four_months', 270:'year'}\n",
    "data_dir = join('data/') \n",
    "final_data_dir = join(data_dir + 'final/')\n",
    "\n",
    "prefix = 'stock-trend-predictor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sagemaker_session.upload_data(final_data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "for t in time_range:\n",
    "    estimator = PyTorch(entry_point='train.py',\n",
    "                        source_dir='source',\n",
    "                        framework_version=1.0, \n",
    "                        role=role,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.p2.xlarge',\n",
    "                        sagemaker_session=sagemaker_session)\n",
    "    estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-18 21:41:44 Starting - Starting the training job...\n",
      "2019-10-18 21:41:45 Starting - Launching requested ML instances...\n",
      "2019-10-18 21:42:43 Starting - Preparing the instances for training.........\n",
      "2019-10-18 21:44:01 Downloading - Downloading input data...\n",
      "2019-10-18 21:44:26 Training - Downloading the training image...\n",
      "2019-10-18 21:45:09 Training - Training image download completed. Training in progress..\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:09,664 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:09,688 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:11,116 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:11,343 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:11,343 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:11,344 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:11,344 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9q9ur2c9/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.3.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-10-18 21:45:13,393 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2019-10-18-21-41-43-885\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-748183850282/sagemaker-pytorch-2019-10-18-21-41-43-885/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-2-748183850282/sagemaker-pytorch-2019-10-18-21-41-43-885/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2019-10-18-21-41-43-885\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-748183850282/sagemaker-pytorch-2019-10-18-21-41-43-885/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing device cuda.\u001b[0m\n",
      "\u001b[31mGet train data loader.\u001b[0m\n",
      "\u001b[31mEpoch: 1, Loss: 0.6817950091906677\u001b[0m\n",
      "\u001b[31mEpoch: 2, Loss: 0.6632568566459658\u001b[0m\n",
      "\u001b[31mEpoch: 3, Loss: 0.6525536416770528\u001b[0m\n",
      "\u001b[31mEpoch: 4, Loss: 0.6509439814490093\u001b[0m\n",
      "\u001b[31mEpoch: 5, Loss: 0.6489545988242987\u001b[0m\n",
      "\u001b[31mEpoch: 6, Loss: 0.6468191370672683\u001b[0m\n",
      "\u001b[31mEpoch: 7, Loss: 0.6467380508705481\u001b[0m\n",
      "\u001b[31mEpoch: 8, Loss: 0.6458189883434893\u001b[0m\n",
      "\u001b[31mEpoch: 9, Loss: 0.644541195992494\u001b[0m\n",
      "\n",
      "2019-10-18 21:47:41 Uploading - Uploading generated training model\n",
      "2019-10-18 21:47:41 Completed - Training job completed\n",
      "\u001b[31mEpoch: 10, Loss: 0.642193054750482\u001b[0m\n",
      "\u001b[31m2019-10-18 21:47:32,325 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 220\n",
      "Billable seconds: 220\n"
     ]
    }
   ],
   "source": [
    "for t, estimator in zip(time_range, estimators):\n",
    "    estimator.fit({'training': data+'/'+time_words[t]+'/train.csv'}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictors = []\n",
    "for estimator in estimators:\n",
    "    predictor = estimator.deploy(1, 'ml.m4.xlarge', wait=False)\n",
    "    predictors.append(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, predictor in zip(time_range, predictors):\n",
    "    # read in test data, assuming it is stored locally\n",
    "    test_data = pd.read_csv(join(final_data_dir, time_words[t]+\"/test.csv\"), header=None, names=None)\n",
    "    # labels are in the first column\n",
    "    test_y = test_data.iloc[:,0]\n",
    "    test_x = test_data.iloc[:,1:]\n",
    "\n",
    "    # First: generate predicted, class labels\n",
    "    \n",
    "    test_y_preds_ = predictor.predict(test_x)\n",
    "    test_y_preds = test_y_preds_.round()\n",
    "\n",
    "\n",
    "    # Second: calculate the test accuracy\n",
    "\n",
    "    accuracy = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for y, y_ in zip(test_y, test_y_preds):\n",
    "        accuracy += 1 if y==y_ else 0\n",
    "        fp += 1 if not y and y_ else 0\n",
    "        fn += 1 if y and not y_ else 0\n",
    "\n",
    "    accuracy /= len(test_y)\n",
    "    print(f'\\n\\n{t} DAYS PREDICTION MODEL:')\n",
    "    print('Accuracy: '+str(accuracy))\n",
    "    print('False positives: '+str(fp))\n",
    "    print('False negatives: '+str(fn))\n",
    "\n",
    "    predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
