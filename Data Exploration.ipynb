{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from statistics import mean, mode, median, stdev\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiingo_api_key = os.environ['TIINGO_API_KEY']\n",
    "iex_api_key = os.environ['IEX_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing all tickers listed by NASDAQ-100\n",
    "tickers_file = 'ndxt_tickers.txt'\n",
    "data_dir = 'data/'\n",
    "raw_data_dir = data_dir + 'raw/'\n",
    "processed_data_dir = data_dir + 'processed/'\n",
    "final_data_dir = data_dir + 'final/'\n",
    "time_range = [1, 5, 10, 20, 90, 270]\n",
    "\n",
    "if not os.path.exists(raw_data_dir):\n",
    "    os.makedirs(raw_data_dir)\n",
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir)\n",
    "if not os.path.exists(final_data_dir):\n",
    "    os.makedirs(final_data_dir)\n",
    "for t in time_range:\n",
    "    if not os.path.exists(final_data_dir+str(t)+'/'):\n",
    "            os.makedirs(final_data_dir+str(t)+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the tickers to be used in the data\n",
    "ndxt_tickers = []\n",
    "with open(data_dir+tickers_file) as f:\n",
    "    for ticker in f:\n",
    "        ndxt_tickers.append(ticker.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for downloading data and saving it, use only when necessary\n",
    "'''\n",
    "raw_stock_data_tiingo = []\n",
    "raw_stock_data_iex = []\n",
    "error_tickers = []\n",
    "\n",
    "for ticker in sorted(ndxt_tickers):\n",
    "    try:\n",
    "        raw_stock_data_tiingo.append(pdr.get_data_tiingo(ticker, api_key= tiingo_api_key))\n",
    "    except:\n",
    "        error_tickers.append(ticker)\n",
    "\n",
    "raw_index_data_yahoo = yf.download('^NDXT', period='5y')\n",
    "# Save each stock data in a CSV file\n",
    "for t in raw_stock_data_tiingo:\n",
    "    t.to_csv(raw_data_dir + t.index.values[0][0] + '.csv')\n",
    "raw_index_data_yahoo.to_csv(raw_data_dir + '^NDXT.csv')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read downloaded data from files\n",
    "raw_stock_data = []\n",
    "raw_index_data_filename = '^NDXT.csv'\n",
    "raw_stock_data_filenames = [f+'.csv' for f in ndxt_tickers]\n",
    "raw_index_df = pd.read_csv(raw_data_dir + raw_index_data_filename)\n",
    "\n",
    "for filename in raw_stock_data_filenames:\n",
    "    raw_stock_data.append(pd.read_csv(raw_data_dir + filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for incomplete(dates) stocks and remove them\n",
    "stock_record_count = mode([len(data) for data in raw_stock_data] + [len(raw_index_df)])\n",
    "for i, t in enumerate(raw_stock_data):\n",
    "    if len(t) != stock_record_count: \n",
    "        raw_stock_data.pop(i)\n",
    "        print('Element removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "for i, t in enumerate(raw_stock_data):\n",
    "    if t.isnull().any().any(): print('Missing data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has equal dates in all rows: True\n"
     ]
    }
   ],
   "source": [
    "# Check that all stock data have the same dates, not the most optimal way to calculate it yet since its O(n^2)\n",
    "equal = True\n",
    "for i in range(len(raw_stock_data)):\n",
    "    for j in range(len(raw_stock_data)):\n",
    "        if not (raw_stock_data[i]['date'] == raw_stock_data[j]['date']).all(): equal = False\n",
    "print('Data has equal dates in all rows: ' + str(equal))\n",
    "assert equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reformat date in stocks dataframes \n",
    "for data in raw_stock_data:\n",
    "    data['date'] = data['date'].map(lambda x: x.split()[0])\n",
    "    \n",
    "# Reformat date in index dataframe\n",
    "#mon_to_num = {'Jan':'01', 'Feb':'02', 'Mar':'03', 'Apr':'04', 'May':'05', 'Jun':'06', 'Jul':'07', 'Aug':'08', 'Sep':'09', 'Oct':'10', 'Nov':'11', 'Dec':'12'}\n",
    "\n",
    "#raw_index_df['Date'] = raw_index_df['Date'].map(lambda x: x.split()[2]+'-'+ mon_to_num[x.split()[0]] +'-'+x.split()[1].strip(','))\n",
    "\n",
    "raw_index_df.drop(columns='Volume', inplace=True)\n",
    "\n",
    "# Rename index columns\n",
    "raw_index_df.columns = ['date', 'open', 'high', 'low', 'close', 'adjClose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign symbol and date as index identifiers for every stock record\n",
    "\n",
    "for data in raw_stock_data:\n",
    "    data.set_index(['symbol', 'date'], inplace=True, drop=True)\n",
    "    \n",
    "# Assign date as index identifier for index records as well\n",
    "\n",
    "raw_index_df.set_index(['date'], inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Concatenate all stock datadrames into one\n",
    "\n",
    "#raw_stock_df = pd.concat(raw_stock_data)\n",
    "\n",
    "\n",
    "# Remove unnecessary information\n",
    "\n",
    "for df in raw_stock_data: df.drop(columns=['divCash', 'splitFactor'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-15\n",
      "2014-10-16\n"
     ]
    }
   ],
   "source": [
    "# Find the oldest final date and newest starting date\n",
    "\n",
    "last_dates = [raw_index_df.index[-1]]\n",
    "first_dates = [raw_index_df.index[0]]\n",
    "\n",
    "for df in raw_stock_data:\n",
    "    dates = []\n",
    "    \n",
    "    for idx in df.index:\n",
    "        dates.append(idx[1])\n",
    "    \n",
    "    last_dates.append(max(dates))\n",
    "    first_dates.append(min(dates))\n",
    "\n",
    "last_date = min(last_dates)\n",
    "first_date = max(first_dates)\n",
    "print(last_date)\n",
    "print(first_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both DataFrames have the same final date (as close to today as possible)\n",
    "while(raw_index_df.index[0] > last_date):\n",
    "    raw_index_df.pop(raw_index_df.index[0])\n",
    "\n",
    "while(raw_index_df.index[-1] < first_date):\n",
    "    raw_index_df.pop(raw_index_df.index[-1])\n",
    "        \n",
    "for df in raw_stock_data:\n",
    "    while(df.index[0][1] > last_date):\n",
    "        df.pop(df.index[0])\n",
    "    while(df.index[-1][1] < first_date):\n",
    "        df.pop(df.index[-1])\n",
    "        \n",
    "# Reverse stock and index records\n",
    "for df in raw_stock_data:\n",
    "    df = df.sort_index(ascending=False, inplace=True)\n",
    "raw_index_df = raw_index_df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames have been processed and not considered raw anymore\n",
    "stocks_df = raw_stock_data\n",
    "index_df = pd.DataFrame(raw_index_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(stock_df, since = 1):\n",
    "    stock_df.drop(columns='y_'+str(since), inplace=True, errors='ignore')\n",
    "    labels = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            assert i-since >= 0\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            future = stock_df.iloc[i-since]['close']\n",
    "            labels.append(1 if future>today else 0)\n",
    "        except:\n",
    "            labels.append(None)\n",
    "    stock_df.insert(loc=0, column='y_'+str(since), value=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(stock_df, period = 1):\n",
    "    stock_df.drop(columns='change', inplace=True, errors='ignore')\n",
    "    change = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            previous = stock_df.iloc[i+period]['close']\n",
    "            change.append(100*(today-previous)/previous)\n",
    "        except:\n",
    "            change.append(None)\n",
    "    stock_df.insert(loc=0, column='change', value=change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PMO(stock_df, period = 50):\n",
    "    stock_df.drop(columns='PMO', inplace=True, errors='ignore')\n",
    "    pmo = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            previous = stock_df.iloc[i+period]['close']\n",
    "            pmo.append(today - previous)\n",
    "        except:\n",
    "            pmo.append(None)\n",
    "    stock_df.insert(loc=0, column='PMO', value=pmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(stock_df, period = 50):\n",
    "    stock_df.drop(columns='RSI', inplace=True, errors='ignore')\n",
    "    rsi = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            rsi_value = 0\n",
    "            pos = []\n",
    "            neg = []\n",
    "            \n",
    "            for j in range(period):\n",
    "                change = stock_df.iloc[i+j]['change']\n",
    "                if change > 0: \n",
    "                    pos.append(change)\n",
    "                elif change < 0: \n",
    "                    neg.append(abs(change))\n",
    "                    \n",
    "            if not neg:\n",
    "                rsi_value = 100\n",
    "            elif not pos:\n",
    "                rsi_value = 0\n",
    "            else:\n",
    "                pos = sum(pos)/len(pos)\n",
    "                neg = sum(neg)/len(neg)\n",
    "                rsi_value = 100 - (100/(1+(pos/neg)))\n",
    "            rsi.append(rsi_value)\n",
    "        except:\n",
    "            rsi.append(None)\n",
    "    stock_df.insert(loc=0, column='RSI', value=rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI(stock_df, period = 50):\n",
    "    stock_df.drop(columns='MFI', inplace=True, errors='ignore')\n",
    "    mfi = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            mfi_value = 0\n",
    "            pos = []\n",
    "            neg = []\n",
    "            typical_prices = []\n",
    "            \n",
    "            for j in range(period):\n",
    "                if not typical_prices: typical_prices.append( mean([stock_df.iloc[i+1]['high'] , stock_df.iloc[i+1]['low'] , stock_df.iloc[i+1]['close']]) ) \n",
    "                tp = (stock_df.iloc[i+j]['high'] + stock_df.iloc[i+j]['low'] + stock_df.iloc[i+j]['close']) / 3\n",
    "                if tp > typical_prices[-1]: \n",
    "                    pos.append( tp * stock_df.iloc[i+j]['volume'] )\n",
    "                elif tp < typical_prices[-1]: \n",
    "                    neg.append( tp * stock_df.iloc[i+j]['volume'] )\n",
    "            \n",
    "            if not neg:\n",
    "                mfi_value = 100\n",
    "            elif not pos:\n",
    "                mfi_value = 0\n",
    "            else:\n",
    "                pos = sum(pos)/len(pos)\n",
    "                neg = sum(neg)/len(neg)\n",
    "                mfi_value = 100 - (100/(1+(pos/neg)))\n",
    "            mfi.append(mfi_value)\n",
    "        except:\n",
    "            mfi.append(None)\n",
    "    stock_df.insert(loc=0, column='MFI', value=mfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(stock_df, period=50):\n",
    "    stock_df.drop(columns='EMA', inplace=True, errors='ignore')\n",
    "    a = 2/(period + 1)\n",
    "    # There are many ways to calculate the first term of an exponential moving average, so for now\n",
    "    # I'll be using the average of the previous 3 closes\n",
    "    initial_value_range = 3\n",
    "    ema = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        emas = []\n",
    "        try:\n",
    "            \n",
    "            for j in list(reversed(range(period))):\n",
    "                if not emas: emas.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a * tc) + ((1 - a) * emas[-1])\n",
    "                emas.append(this_ema)\n",
    "            \n",
    "            ema.append(emas[-1])\n",
    "        except:\n",
    "            ema.append(None)\n",
    "    stock_df.insert(loc=0, column='EMA', value=ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SO(stock_df, period=50):\n",
    "    stock_df.drop(columns='SO', inplace=True, errors='ignore')\n",
    "    \n",
    "    so = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            tc = stock_df.iloc[i]['close']\n",
    "            ll = min([stock_df.iloc[i+day]['low'] for day in range(period)])\n",
    "            hh = max([stock_df.iloc[i+day]['high'] for day in range(period)])\n",
    "            this_so = ((tc - ll) / (hh - ll)) * 100\n",
    "            so.append(this_so)\n",
    "        except:\n",
    "            so.append(None)\n",
    "    \n",
    "    stock_df.insert(loc=0, column='SO', value=so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(stock_df, p1=12, p2=26):\n",
    "    stock_df.drop(columns='MACD', inplace=True, errors='ignore')\n",
    "    \n",
    "    a1 = 2/(p1 + 1)\n",
    "    a2 = 2/(p2 + 1)\n",
    "    initial_value_range = 3\n",
    "    macd = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        ema1 = []\n",
    "        ema2 = []\n",
    "        try:\n",
    "            for j in list(reversed(range(p1))):\n",
    "                if not ema1: ema1.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a1 * tc) + ((1 - a1) * ema1[-1])\n",
    "                ema1.append(this_ema)\n",
    "            \n",
    "            for j in list(reversed(range(p2))):\n",
    "                if not ema2: ema2.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a2 * tc) + ((1 - a2) * ema2[-1])\n",
    "                ema2.append(this_ema)\n",
    "            \n",
    "            macd.append(ema1[-1] - ema2[-1])\n",
    "            \n",
    "        except:\n",
    "            macd.append(None)\n",
    "    \n",
    "    stock_df.insert(loc=0, column='MACD', value=macd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate features for index data, MFI is not calculated as it requires volume\n",
    "\n",
    "change(index_df)\n",
    "MACD(index_df)\n",
    "SO(index_df, 10)\n",
    "EMA(index_df, 10)\n",
    "RSI(index_df, 10)\n",
    "PMO(index_df, 10)\n",
    "index_df.fillna(value=pd.np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3% 5% "
     ]
    }
   ],
   "source": [
    "# Calculate features and labels for stock data, this takes a lot of time\n",
    "i=0\n",
    "for df in stocks_df:\n",
    "    i += 1\n",
    "    change(df)\n",
    "    MACD(df)\n",
    "    SO(df, 10)\n",
    "    EMA(df, 10)\n",
    "    MFI(df, 10)\n",
    "    RSI(df, 10)\n",
    "    PMO(df, 10)\n",
    "    for m in [1, 5, 10, 20, 90, 270]:\n",
    "        labels(df, m)\n",
    "    df.fillna(value=pd.np.nan, inplace=True)\n",
    "    print(f'{round(i*100/len(ndxt_tickers))}% ', end='')\n",
    "    \n",
    "#for df in stocks_df:\n",
    "#    df.dropna(inplace=True)\n",
    "\n",
    "stocks_df[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data as a milestone\n",
    "\n",
    "index_df.to_csv(processed_data_dir+ '^NDXT.csv')\n",
    "for df in stocks_df:\n",
    "    df.to_csv(processed_data_dir+ f'{df.index[0][0]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "idf = index_df[['PMO', 'EMA', 'MACD']]\n",
    "scaler.fit(idf)\n",
    "index_df[['PMO', 'EMA', 'MACD']] = scaler.transform(idf)\n",
    "idf = index_df[['RSI', 'SO']]\n",
    "index_df[['RSI', 'SO']] = idf/100\n",
    "\n",
    "for i, df_ in enumerate(stocks_df):\n",
    "    df = df_[['PMO', 'EMA', 'MACD']]\n",
    "    scaler.fit(df)\n",
    "    stocks_df[i][['PMO', 'EMA', 'MACD']] = scaler.transform(df)\n",
    "    df = df_[['RSI' ,'MFI', 'SO']]\n",
    "    stocks_df[i][['RSI' ,'MFI', 'SO']] = df/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack([stocks_df[0][['y_'+str(1), 'PMO', 'EMA', 'MACD', 'RSI' ,'MFI', 'SO']].to_numpy(), index_df[['PMO', 'EMA', 'MACD', 'RSI', 'SO']].to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([stocks_df[0][['y_'+str(1), 'PMO', 'EMA', 'MACD', 'RSI' ,'MFI', 'SO']], index_df[['PMO', 'EMA', 'MACD', 'RSI', 'SO']].reset_index().drop(columns='date')], sort=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify all data into separate training/testing sets\n",
    "\n",
    "test_train_separation = round(len(stocks_df[0])*2/3)\n",
    "\n",
    "for t in time_range:\n",
    "    new_df_list = []\n",
    "    \n",
    "    for df in stocks_df:\n",
    "        new_df_list.append(pd.concat([df[['y_'+str(t), 'PMO', 'EMA', 'MACD', 'RSI' ,'MFI', 'SO']], index_df[['PMO', 'EMA', 'MACD', 'RSI', 'SO']]], axis=1))\n",
    "    \n",
    "    for dataset in new_df_list:\n",
    "        dataset.iloc[:test_train_separation].to_csv(final_data_dir+str(t)+'/train.csv')\n",
    "        dataset.iloc[test_train_separation:].to_csv(final_data_dir+str(t)+'/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To think about\n",
    "\n",
    "## How to sum up data into feedable features\n",
    "* Definitely by record\n",
    "## Labels are per row? per group of rows?\n",
    "* Smaller groups -> more input data.\n",
    "* These groups are n_1 and n_2 for stocks and index respectively.\n",
    "\n",
    "## Categorical labels for low to high increase/decrease\n",
    "\n",
    "## Should all features be normalized? how?\n",
    "Yes, absolutely. MinMax normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
