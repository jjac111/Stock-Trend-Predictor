{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Trend Predictor\n",
    "__Juan Javier Arosemena__\n",
    "## Introduction \n",
    "As the knowledge and techniques surrounding machine learning increase, the interest in applying this knowledge to stock data for making predictions is growing as well. The stock market is a composition of buyers and sellers of stocks, which are units for representing partial ownership of a company. These stocks have a specified price which can vary each day and minute, and it is affected by unpredictable factors such as politics, social trends, the environment, and company-related events.\n",
    "Stock data is information that represents the movement of stock prices for given companies (or market indexes such as S&P 500, NASDAQ-100) for each day that the stock market operates. \n",
    "\n",
    "Stock data usually has 7 main data fields per day:\n",
    "\n",
    "* Date: the date of the stock data for that day\n",
    "* Open: the price of the first stock transaction made after market opens\n",
    "* High: the highest price of the stock\n",
    "* Low: the lowest price of the stock\n",
    "* Close: the price of the first stock transaction made before market closes\n",
    "* Volume: the number of stocks traded that day\n",
    "* Adjusted Close: the closing price of a stock after considering corporate actions\n",
    "\n",
    "Based on this data and derived data, financial analysts can make technichal analysis for the direction that the stock prices will take and, therefore, make decisions on buying and selling stocks with the lowest possible risk.\n",
    "\n",
    "In stock market theory, it is said that the market follows the _Efficient Markets Hypothesis_, which states that the market “follows a random walk and can be unpredictable based on historical data” ([Madge, 2015](https://www.cs.princeton.edu/sites/default/files/uploads/saahil_madge.pdf)). This holds true for stock predictions in the short term, however, it is possible to find patterns in stock data in long periods of time, which in turn means that there is a degree of predictableness in the stock market.\n",
    "\n",
    "Taking into account the fact that stock data holds complex patterns that can give information to formulate predictions, the application of __artificial neural networks__ (ANNs) to this data seems to be an appealing task for exploiting the potential of Artificial Intelligence (in fact, big hedge funds already use AI for stock predictions). \n",
    "\n",
    "## Workflow\n",
    "For the development of this project I'm sticking to the Machine Learning Workflow, which has 3 main parts:\n",
    "1. Data Exploration\n",
    "    * Data retrieval\n",
    "    * Feature engineering\n",
    "    * Data preprocessing and creation of ANN feedable features.\n",
    "2. Model Training\n",
    "    * AI model definition\n",
    "    * Training and validation\n",
    "    * Parameter tuning\n",
    "    * Model selection.\n",
    "3. Model Deployment\n",
    "    * Deployment of trained model.\n",
    "    * Deployed model evaluation.\n",
    "    * Model update.\n",
    "![The machine learning workflow, Amazon Web Services](https://docs.aws.amazon.com/sagemaker/latest/dg/images/ml-concepts-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Data Exploration consists of the entire process of finding your data, convert it into data that can be manipulated in code, extracting features from the data, clean it,  and finally constructing files that contain directly feedable features for an ANN or any machine learning model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96b434962da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from statistics import mean, mode, median, stdev\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieval\n",
    "For this project I chose 3 data sources:\n",
    "1. Tiingo: A financial research platform dedicated to creating innovative financial tools, which provides an API for downloading stock data.\n",
    "2. IEX: Investors Exchange is a fair, simple and transparent stock exchange dedicated to investor and issuer protection, and also provides an API.\n",
    "3. Yahoo Finance: It provides financial news, data and commentary including stock quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to download data from Tiingo and IEX we must provide an API key, \n",
    "# which can be found in your site's respective account page.\n",
    "# My account's keys are stored as environment variables and correspond to free accounts.\n",
    "\n",
    "tiingo_api_key = os.environ['TIINGO_API_KEY']\n",
    "iex_api_key = os.environ['IEX_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing all tickers listed by NASDAQ-100 Technology index. \n",
    "\n",
    "tickers_file = 'ndxt_tickers.txt'\n",
    "\n",
    "\n",
    "# Directory tree to create for data processing.\n",
    "\n",
    "data_dir = 'data/' #this directory must already exist.\n",
    "raw_data_dir = data_dir + 'raw/'\n",
    "processed_data_dir = data_dir + 'processed/'\n",
    "final_data_dir = data_dir + 'final/'\n",
    "\n",
    "\n",
    "# We will train different models that can predict different time ranges in the stock calendar.\n",
    "\n",
    "time_range = [1, 5, 10, 20, 90, 270]\n",
    "periods = [5, 10, 20, 90, 270]\n",
    "time_words = {1:'day', 5:'week', 10:'two_weeks', 20:'month', 90:'four_months', 270:'year'}\n",
    "\n",
    "\n",
    "# Make directories\n",
    "\n",
    "if not os.path.exists(raw_data_dir):\n",
    "    os.makedirs(raw_data_dir)\n",
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir)\n",
    "if not os.path.exists(final_data_dir):\n",
    "    os.makedirs(final_data_dir)\n",
    "for n1 in periods:\n",
    "    for n2 in periods:\n",
    "        if not os.path.exists(processed_data_dir+f'/{n1}_{n2}/'):\n",
    "            os.makedirs(processed_data_dir+f'/{n1}_{n2}/')\n",
    "for t in time_range:\n",
    "    for n1 in periods:\n",
    "        for n2 in periods:\n",
    "            if not os.path.exists(final_data_dir+time_words[t]+f'/{n1}_{n2}/'):\n",
    "                os.makedirs(final_data_dir+time_words[t]+f'/{n1}_{n2}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the stock tickers to be downloaded\n",
    "\n",
    "ndxt_tickers = []\n",
    "with open(data_dir+tickers_file) as f:\n",
    "    for ticker in f:\n",
    "        ndxt_tickers.append(ticker.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data is downloaded and directly transformed into a ``pandas.DataFrame``. Immediately after downloading, the raw data is saved into ``.csv`` files.\n",
    "The data to be downloaded are all the possible stock quotes from companies that are indexed by the _NASDAQ-100 Technology Sector_(^NDXT), as well as the index data itself. Since we are using free accounts to retrieve the data from the mentioned API's, the time range for all downloaded data is the limit of 5 years previous to the current date.\n",
    "As for the ^NDXT data, we are using the ``yfinance`` library created by [Ran Aroussi](https://pypi.org/project/yfinance/). \n",
    "\n",
    "Do not abuse the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for downloading data and saving it, use only when necessary\n",
    "\n",
    "raw_stock_data_tiingo = []\n",
    "raw_stock_data_iex = []\n",
    "error_tickers = []\n",
    "\n",
    "for ticker in sorted(ndxt_tickers):\n",
    "    try:\n",
    "        raw_stock_data_tiingo.append(pdr.get_data_tiingo(ticker, api_key= tiingo_api_key))\n",
    "    except:\n",
    "        error_tickers.append(ticker)\n",
    "else: \n",
    "    if error_tickers:\n",
    "        try:\n",
    "            for ticker in error_tickers:\n",
    "                raw_stock_data_iex.append(pdr.get_markets_iex(ticker, api_key= tiingo_api_key))\n",
    "        except:\n",
    "            print(ticker+ ' was not downloaded.')\n",
    "raw_index_data_yahoo = yf.download('^NDXT', period='5y')\n",
    "\n",
    "\n",
    "# Save each stock data in a CSV file\n",
    "\n",
    "for t in raw_stock_data_tiingo:\n",
    "    t.to_csv(raw_data_dir + t.index.values[0][0] + '.csv')\n",
    "    \n",
    "for t in raw_stock_data_iex:\n",
    "    t.to_csv(raw_data_dir + t.index.values[0][0] + '.csv')\n",
    "    \n",
    "raw_index_data_yahoo.to_csv(raw_data_dir + '^NDXT.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read downloaded data from files\n",
    "\n",
    "raw_stock_data = []\n",
    "raw_index_data_filename = '^NDXT.csv'\n",
    "raw_stock_data_filenames = [f+'.csv' for f in ndxt_tickers]\n",
    "raw_index_df = pd.read_csv(raw_data_dir + raw_index_data_filename)\n",
    "\n",
    "for filename in raw_stock_data_filenames:\n",
    "    raw_stock_data.append(pd.read_csv(raw_data_dir + filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "In order to manipulate the retireved data, it is necessary to give it structure.\n",
    "\n",
    "``raw_stock_data`` is a list containing all stock dataframes, and ``raw_index_df`` is the dataframe containing the ^NDXT data. For every dataframe, their index will be the dates of each stock or index quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reformat date in stocks dataframes, remove time\n",
    "\n",
    "for data in raw_stock_data:\n",
    "    data['date'] = data['date'].map(lambda x: x.split()[0])\n",
    "\n",
    "    \n",
    "# Volume is not a given data for the index quotes.\n",
    "\n",
    "raw_index_df.drop(columns='Volume', inplace=True)\n",
    "\n",
    "\n",
    "# Rename index columns to lowercase\n",
    "\n",
    "raw_index_df.columns = ['date', 'open', 'high', 'low', 'close', 'adjClose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every stock dataframe will also contain its ticker symbol as part of their index. Also remove unnecessary information like dividends and splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign symbol and date as index identifiers for every stock record\n",
    "\n",
    "for data in raw_stock_data:\n",
    "    data.set_index(['symbol', 'date'], inplace=True, drop=True)\n",
    "    \n",
    "# Assign date as index identifier for index records as well\n",
    "\n",
    "raw_index_df.set_index(['date'], inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Remove unnecessary information\n",
    "\n",
    "for df in raw_stock_data: df.drop(columns=['divCash', 'splitFactor'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very crucial part for following data processing if making sure that every dataframe, both stocks and index, contain the same ranges of data. This is because the final features will be a mix of individual stock quotes with index quotes. Since we are not guaranteed that all the downloaded data contains the same time ranges, we must find the oldest last date among all quotes, and also the newest first date for all data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-15\n",
      "2014-10-16\n"
     ]
    }
   ],
   "source": [
    "# Find the oldest final date and newest starting date\n",
    "\n",
    "last_dates = [raw_index_df.index[-1]]\n",
    "first_dates = [raw_index_df.index[0]]\n",
    "\n",
    "for df in raw_stock_data:\n",
    "    dates = []\n",
    "    \n",
    "    for idx in df.index:\n",
    "        dates.append(idx[1])\n",
    "    \n",
    "    last_dates.append(max(dates))\n",
    "    first_dates.append(min(dates))\n",
    "\n",
    "last_date = min(last_dates)\n",
    "first_date = max(first_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the found time ranges, we can trim the dataframes to make sure they all contain the same respective dates for their data. Then, reverse dataframes so that the latest quote comes first, and the oldest quote goes last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both DataFrames have the same final date (as close to today as possible)\n",
    "\n",
    "while(raw_index_df.index[0] > last_date):\n",
    "    raw_index_df.pop(raw_index_df.index[0])\n",
    "\n",
    "while(raw_index_df.index[-1] < first_date):\n",
    "    raw_index_df.pop(raw_index_df.index[-1])\n",
    "        \n",
    "for df in raw_stock_data:\n",
    "    while(df.index[0][1] > last_date):\n",
    "        df.pop(df.index[0])\n",
    "    while(df.index[-1][1] < first_date):\n",
    "        df.pop(df.index[-1])\n",
    "        \n",
    "        \n",
    "# Reverse stock and index records\n",
    "\n",
    "for df in raw_stock_data:\n",
    "    df = df.sort_index(ascending=False, inplace=True)\n",
    "raw_index_df = raw_index_df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Now that all the raw data has been transformed into explorable data, we can extract and compute information that we want to feed our machine learning model. \n",
    "\n",
    "The features to be calculated for stock and index data are the following:\n",
    "1. Price Momentum Oscillator = TC – PPC\n",
    "    * TC: today’s close\n",
    "    * PPC: previous period’s close\n",
    "    \n",
    "\n",
    "\n",
    "2. Relative Strength Index = 100 – [100/(1 + RS)]\n",
    "    * RS: average of x days up-closes divided by average of x days down-closes\n",
    "\n",
    "\n",
    "3. Money Flow Index = 100 *(100/(1 + MR))\n",
    "    * MR = (PositiveMF / NegativeMF)\n",
    "    * MF = TP * Volume\n",
    "    * TP: average of high, low, and close prices for a given period. If the current Typical Price is greater than the previous period’s, it is considered Positive Money Flow.\n",
    "    \n",
    "    \n",
    "4. Exponential Moving Average = [α * TC] + [(1 – α) * YEMA]\n",
    "    * TC: today’s close\n",
    "    * YEMA: yesterday’s exponential moving average\n",
    "    * α: smoothing factor which is 2/(n+1) where n is the number of days in the period.\n",
    "    \n",
    "    \n",
    "5. Stochastic Oscillator = [(CP - LP) / (HP - LP)]*100\n",
    "    * CP: closing price\n",
    "    * LP: lowest low price in the period\n",
    "    * HP: highest high price in the period\n",
    "    \n",
    "    \n",
    "6. Moving Average Convergence/Divergence = (12-day EMA) – (26-day EMA)\n",
    "\n",
    "\n",
    "These features where proposed by [Abdul Salam, Emary, and Zawbaa (2018)](https://www.researchgate.net/publication/324029737_A_Hybrid_Moth-Flame_Optimization_and_Extreme_Learning_Machine_Model_for_Financial_Forecasting?enrichId=rgreq-72e17bad737cd78e1c16dfa2b01ab9a9-XXX&enrichSource=Y292ZXJQYWdlOzMyNDAyOTczNztBUzo2MDg2ODg5OTc5MzcxNTlAMTUyMjEzNDE3NDQ4Mg%3D%3D&el=1_x_2&_esc=publicationCoverPdf) in their paper for a machine learning model for stock market prediction.\n",
    "\n",
    "We will stick to 6 time ranges to use for label calculations as proposed by Madge: \n",
    "1. One day\n",
    "2. One week\n",
    "3. Two weeks\n",
    "4. One month\n",
    "5. Four months\n",
    "6. One year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(stock_df, since = 1):\n",
    "    '''Function for labeling the trend in stock data given a period of time.\n",
    "    \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            since (int): time period for which to label trend.\n",
    "        \n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with labels 1 for incresing close price after 'since' days, 0 otherwise.\n",
    "    '''\n",
    "    stock_df.drop(columns='y_'+str(since), inplace=True, errors='ignore')\n",
    "    labels = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            assert i-since >= 0\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            future = stock_df.iloc[i-since]['close']\n",
    "            labels.append(1 if future>today else 0)\n",
    "        except:\n",
    "            labels.append(None)\n",
    "    stock_df.insert(loc=0, column='y_'+str(since), value=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(stock_df, period = 1):\n",
    "    '''Function for calculating the change percentage of closing prices since 'period' days ago.\n",
    "    \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            period (int): time period for which to calculate change.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with change percentage.\n",
    "    '''\n",
    "    stock_df.drop(columns='change', inplace=True, errors='ignore')\n",
    "    change = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            previous = stock_df.iloc[i+period]['close']\n",
    "            change.append(100*(today-previous)/previous)\n",
    "        except:\n",
    "            change.append(None)\n",
    "    stock_df.insert(loc=0, column='change', value=change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PMO(stock_df, period = 50):\n",
    "    '''Price Momentum Oscillator.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with PMO.\n",
    "    '''\n",
    "    stock_df.drop(columns='PMO', inplace=True, errors='ignore')\n",
    "    pmo = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            today = stock_df.iloc[i]['close']\n",
    "            previous = stock_df.iloc[i+period]['close']\n",
    "            pmo.append(today - previous)\n",
    "        except:\n",
    "            pmo.append(None)\n",
    "    stock_df.insert(loc=0, column='PMO', value=pmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(stock_df, period = 50):\n",
    "    '''Relative Strength Index.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a columns 'close' for the closing prices and 'change' in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with RSI.\n",
    "    '''\n",
    "    stock_df.drop(columns='RSI', inplace=True, errors='ignore')\n",
    "    rsi = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            rsi_value = 0\n",
    "            pos = []\n",
    "            neg = []\n",
    "            \n",
    "            for j in range(period):\n",
    "                change = stock_df.iloc[i+j]['change']\n",
    "                if change > 0: \n",
    "                    pos.append(change)\n",
    "                elif change < 0: \n",
    "                    neg.append(abs(change))\n",
    "                    \n",
    "            if not neg:\n",
    "                rsi_value = 100\n",
    "            elif not pos:\n",
    "                rsi_value = 0\n",
    "            else:\n",
    "                pos = sum(pos)/len(pos)\n",
    "                neg = sum(neg)/len(neg)\n",
    "                rsi_value = 100 - (100/(1+(pos/neg)))\n",
    "            rsi.append(rsi_value)\n",
    "        except:\n",
    "            rsi.append(None)\n",
    "    stock_df.insert(loc=0, column='RSI', value=rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI(stock_df, period = 50):\n",
    "    '''Money Flow Index.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a columns 'close' for the closing prices and 'volume', 'high', and 'low' in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with MFI.\n",
    "    '''\n",
    "    stock_df.drop(columns='MFI', inplace=True, errors='ignore')\n",
    "    mfi = []\n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            mfi_value = 0\n",
    "            pos = []\n",
    "            neg = []\n",
    "            typical_prices = []\n",
    "            \n",
    "            for j in range(period):\n",
    "                if not typical_prices: typical_prices.append( mean([stock_df.iloc[i+1]['high'] , stock_df.iloc[i+1]['low'] , stock_df.iloc[i+1]['close']]) ) \n",
    "                tp = (stock_df.iloc[i+j]['high'] + stock_df.iloc[i+j]['low'] + stock_df.iloc[i+j]['close']) / 3\n",
    "                if tp > typical_prices[-1]: \n",
    "                    pos.append( tp * stock_df.iloc[i+j]['volume'] )\n",
    "                elif tp < typical_prices[-1]: \n",
    "                    neg.append( tp * stock_df.iloc[i+j]['volume'] )\n",
    "            \n",
    "            if not neg:\n",
    "                mfi_value = 100\n",
    "            elif not pos:\n",
    "                mfi_value = 0\n",
    "            else:\n",
    "                pos = sum(pos)/len(pos)\n",
    "                neg = sum(neg)/len(neg)\n",
    "                mfi_value = 100 - (100/(1+(pos/neg)))\n",
    "            mfi.append(mfi_value)\n",
    "        except:\n",
    "            mfi.append(None)\n",
    "    stock_df.insert(loc=0, column='MFI', value=mfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(stock_df, period=50):\n",
    "    '''Exponential Moving Average.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with EMA.\n",
    "    '''\n",
    "    stock_df.drop(columns='EMA', inplace=True, errors='ignore')\n",
    "    a = 2/(period + 1)\n",
    "    # There are many ways to calculate the first term of an exponential moving average, so for now\n",
    "    # I'll be using the average of the previous 3 closes\n",
    "    initial_value_range = 3\n",
    "    ema = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        emas = []\n",
    "        try:\n",
    "            \n",
    "            for j in list(reversed(range(period))):\n",
    "                if not emas: emas.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a * tc) + ((1 - a) * emas[-1])\n",
    "                emas.append(this_ema)\n",
    "            \n",
    "            ema.append(emas[-1])\n",
    "        except:\n",
    "            ema.append(None)\n",
    "    stock_df.insert(loc=0, column='EMA', value=ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SO(stock_df, period=50):\n",
    "    '''Stochastic Oscillator.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices, 'high', and 'low' in historical stock data.\n",
    "            period (int): time period for which to calculate.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with PMO.\n",
    "    '''\n",
    "    stock_df.drop(columns='SO', inplace=True, errors='ignore')\n",
    "    \n",
    "    so = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        try:\n",
    "            tc = stock_df.iloc[i]['close']\n",
    "            ll = min([stock_df.iloc[i+day]['low'] for day in range(period)])\n",
    "            hh = max([stock_df.iloc[i+day]['high'] for day in range(period)])\n",
    "            this_so = ((tc - ll) / (hh - ll)) * 100\n",
    "            so.append(this_so)\n",
    "        except:\n",
    "            so.append(None)\n",
    "    \n",
    "    stock_df.insert(loc=0, column='SO', value=so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD(stock_df, p1=12, p2=26):\n",
    "    '''Moving Average Convergence/Divergence.\n",
    "        \n",
    "        Args:\n",
    "            stocks_df (pandas.DataFrame): contains a column 'close' for the closing prices in historical stock data.\n",
    "            p1 (int): time period for which to calculate first EMA.\n",
    "            p2 (int): time period for which to calculate second EMA.\n",
    "        Returns:\n",
    "            None: the passed DataFrame will have a new column with PMO.\n",
    "    '''\n",
    "    stock_df.drop(columns='MACD', inplace=True, errors='ignore')\n",
    "    \n",
    "    a1 = 2/(p1 + 1)\n",
    "    a2 = 2/(p2 + 1)\n",
    "    initial_value_range = 3\n",
    "    macd = []\n",
    "    \n",
    "    for i in range(len(stock_df)):\n",
    "        ema1 = []\n",
    "        ema2 = []\n",
    "        try:\n",
    "            for j in list(reversed(range(p1))):\n",
    "                if not ema1: ema1.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a1 * tc) + ((1 - a1) * ema1[-1])\n",
    "                ema1.append(this_ema)\n",
    "            \n",
    "            for j in list(reversed(range(p2))):\n",
    "                if not ema2: ema2.append( mean([stock_df.iloc[i+j+day]['close'] for day in range(initial_value_range)]) )\n",
    "                tc = stock_df.iloc[i+j]['close']\n",
    "                this_ema = (a2 * tc) + ((1 - a2) * ema2[-1])\n",
    "                ema2.append(this_ema)\n",
    "            \n",
    "            macd.append(ema1[-1] - ema2[-1])\n",
    "            \n",
    "        except:\n",
    "            macd.append(None)\n",
    "    \n",
    "    stock_df.insert(loc=0, column='MACD', value=macd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the enormous possibilities of mixing time ranges for features for both index and stock data (around 125 different datasets), as proposed by Madge, we will use features calculated with a single time period of 20 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for n1 in periods:\n",
    "    for n2 in periods:\n",
    "        i+=1\n",
    "        stocks_df = [df.copy() for df in raw_stock_data]\n",
    "        index_df = raw_index_df.copy()\n",
    "\n",
    "        # Calculate features for index data, MFI is not calculated as it requires volume\n",
    "\n",
    "        change(index_df)\n",
    "        MACD(index_df, n1, 2*n1)\n",
    "        SO(index_df, n1)\n",
    "        EMA(index_df, n1)\n",
    "        RSI(index_df, n1)\n",
    "        PMO(index_df, n1)\n",
    "        index_df.fillna(value=pd.np.nan, inplace=True)\n",
    "\n",
    "        # Calculate features and labels for stock data, this takes a lot of time\n",
    "\n",
    "        \n",
    "        for df in stocks_df:\n",
    "            change(df)\n",
    "            MACD(df, n2, 2*n2)\n",
    "            SO(df, n2)\n",
    "            EMA(df, n2)\n",
    "            MFI(df, n2)\n",
    "            RSI(df, n2)\n",
    "            PMO(df, n2)\n",
    "            for m in [1, 5, 10, 20, 90, 270]:\n",
    "                labels(df, m)\n",
    "            df.fillna(value=pd.np.nan, inplace=True)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        # Once feature extraction is finished, saved all processed data locally.\n",
    "\n",
    "        # Save the processed data as a milestone\n",
    "\n",
    "        index_df.to_csv(processed_data_dir+f'{n1}_{n2}/^NDXT.csv')\n",
    "        for df in stocks_df:\n",
    "            df.to_csv(processed_data_dir+ f'{n1}_{n2}/{df.index[0][0]}.csv')\n",
    "\n",
    "        # ANNs require their feeded features to be normalized values. Therefore, we need to convert all features into ranges from [0,1]. For features that represent percenatges we divide them by 100, and for features with arbitrary ranges we scale them with a ``MinMaxScaler``.\n",
    "\n",
    "        # Normalizing features\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        idf = index_df[['PMO', 'EMA', 'MACD']]\n",
    "        scaler.fit(idf)\n",
    "        index_df[['PMO', 'EMA', 'MACD']] = scaler.transform(idf)\n",
    "        idf = index_df[['RSI', 'SO']]\n",
    "        index_df[['RSI', 'SO']] = idf/100\n",
    "\n",
    "        for i, df_ in enumerate(stocks_df):\n",
    "            df = df_[['PMO', 'EMA', 'MACD']]\n",
    "            scaler.fit(df)\n",
    "            stocks_df[i][['PMO', 'EMA', 'MACD']] = scaler.transform(df)\n",
    "            df = df_[['RSI' ,'MFI', 'SO']]\n",
    "            stocks_df[i][['RSI' ,'MFI', 'SO']] = df/100\n",
    "\n",
    "        \n",
    "        # Unify all data into separate training/testing sets\n",
    "\n",
    "        for t in time_range:\n",
    "            train_df_list = []\n",
    "            test_df_list = []\n",
    "\n",
    "            for df in stocks_df:\n",
    "                test_train_separation = round((len(df) + t - max(n1, n2))*2/3)\n",
    "                to_concat_train = [df[['y_'+str(t), 'PMO', 'EMA', 'MACD', 'RSI' ,'MFI', 'SO']].iloc[:test_train_separation], index_df[['PMO', 'EMA', 'MACD', 'RSI', 'SO']].iloc[:test_train_separation]]\n",
    "                to_concat_test = [df[['y_'+str(t), 'PMO', 'EMA', 'MACD', 'RSI' ,'MFI', 'SO']].iloc[test_train_separation:], index_df[['PMO', 'EMA', 'MACD', 'RSI', 'SO']].iloc[test_train_separation:]]\n",
    "                train_df_list.append(pd.concat([s.reset_index(drop=True) for s in to_concat_train], sort=False, axis=1))\n",
    "                test_df_list.append(pd.concat([s.reset_index(drop=True) for s in to_concat_test], sort=False, axis=1))\n",
    "\n",
    "            full_train_df = pd.concat([df for df in train_df_list], axis=0)\n",
    "            full_test_df = pd.concat([df for df in test_df_list], axis=0)\n",
    "\n",
    "            full_train_df.dropna(inplace=True)\n",
    "            full_test_df.dropna(inplace=True)\n",
    "\n",
    "            # Save final data\n",
    "            full_train_df.to_csv(final_data_dir+time_words[t]+f'{n1}_{n2}'+'/train.csv', header=False, index=False)\n",
    "            full_test_df.to_csv(final_data_dir+time_words[t]+f'{n1}_{n2}'+'/test.csv', header=False, index=False)\n",
    "            \n",
    "            print(f'{round(i*100/(len(periods)*len(periods)))}% ', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data preparation\n",
    "Data has been processed and normalized, and is ready to be unified into feedable train and test datasets. \n",
    "We will produce one test and one train dataset for each of the 6 models to be trained, and each record (each stock market day) of each dataset will contain the following structure.\n",
    "1. Label\n",
    "2. Stock PMO\n",
    "3. Stock EMA\n",
    "4. Stock MACD\n",
    "5. Stock RSI\n",
    "6. Stock MFI\n",
    "7. Stock SO\n",
    "8. Index PMO\n",
    "9. Index EMA\n",
    "10. Index MACD\n",
    "11. Index RSI\n",
    "12. Index SO\n",
    "\n",
    "\n",
    "For each stock symbol and each stock date."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
